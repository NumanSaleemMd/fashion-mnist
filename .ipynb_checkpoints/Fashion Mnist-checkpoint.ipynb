{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aiman\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\aiman\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 112s 2ms/sample - loss: 0.4801 - acc: 0.8277 - val_loss: 0.3571 - val_acc: 0.8705\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 110s 2ms/sample - loss: 0.3106 - acc: 0.8867 - val_loss: 0.3134 - val_acc: 0.8892\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 111s 2ms/sample - loss: 0.2575 - acc: 0.9062 - val_loss: 0.2965 - val_acc: 0.8938\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 113s 2ms/sample - loss: 0.2151 - acc: 0.9210 - val_loss: 0.2698 - val_acc: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f00085a898>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "fashion_model=Sequential()\n",
    "fashion_model.add(Conv2D(12,kernel_size=3,activation='relu',input_shape=(img_rows,img_cols,1)))\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(100, activation='relu'))\n",
    "fashion_model.add(Dense(10, activation='softmax'))\n",
    "fashion_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "fashion_model.fit(x,y,batch_size=100,epochs=4,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9875855e-01, 6.4087651e-09, 9.3432856e-05, ..., 1.3004541e-08,\n",
       "        3.7276570e-06, 6.9341910e-10],\n",
       "       [5.6389871e-07, 9.9999750e-01, 1.1598268e-08, ..., 3.3213720e-11,\n",
       "        3.1475645e-07, 5.9662669e-10],\n",
       "       [1.0613258e-02, 4.1748076e-06, 4.9100101e-01, ..., 2.1778540e-06,\n",
       "        3.3490465e-05, 3.1461168e-05],\n",
       "       ...,\n",
       "       [1.2301217e-07, 4.8851936e-11, 6.4549511e-08, ..., 1.1344496e-06,\n",
       "        9.9999857e-01, 2.7843625e-09],\n",
       "       [3.2745446e-03, 1.0460110e-05, 1.5382951e-03, ..., 1.8327681e-05,\n",
       "        9.6606588e-01, 7.8212608e-05],\n",
       "       [3.6723509e-02, 4.6348968e-01, 3.1753417e-02, ..., 2.0763664e-06,\n",
       "        4.6971315e-03, 1.5767486e-05]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_test,y_test=prep_data(np.loadtxt('fashion-mnist_test.csv', skiprows=1, delimiter=','))\n",
    "# y_pred=fashion_model.predict(x_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
